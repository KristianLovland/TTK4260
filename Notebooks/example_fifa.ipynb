{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitbaa70cb6fe3a4090bdd0ead452b1b626",
   "display_name": "Python 3.7.4 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eksempel på multivariat data: FIFA-skillz\n",
    "I dette eksempelet tar jeg for meg et datasett bestående av informasjon om alle spillere på FIFA 20, hentet fra [denne linken](https://www.kaggle.com/stefanoleone992/fifa-20-complete-player-dataset). Antagelsen min er at mange ferdigheter er høyt korrelerte (er man god på langpasninger er man gjerne god på innlegg også, for eksempel), og dermed perfekt å anvende ulike metoder var multivariat analyse på.\n",
    "\n",
    "## Datasett\n",
    "Datasettet består av litt over 18 000 rad, der hver rad inneholder egenskapene til en fotballspiller. Hver kolonne svarer til en bestemt ferdighet. Etter å ha gjort et utvalg av hvilke ferdigheter (kolonner) som er relevante å analysere, sitter vi igjen med et datasett i form av en matrise $X$ som skriker etter å bli analysert.\n",
    "\n",
    "## Avhengigheter og forberedende kode\n",
    "Først importerer vi alle bibliotek vi trenger, forbereder plott, og definerer datasettet vårt. Her fjerner vi alle keepere fordi disse ikke har definert alle ferdigheter vi er interesserte i. Jeg har vært lite streng, og definert alle numeriske verdier som relevante. Dette betyr blant annet at absurde forklaringsvariabler som ``sofifa_id`` er med, men metodene som skal brukes burde uansett være robuste nok til å ignorere disse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lag penere, mer høyoppløselige plott enn seaborn gjør med default-innstillinger\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set(style=\"ticks\", font=\"Latin Modern Math\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"../datasett/fifa-20-complete-player-dataset/players_20.csv\"\n",
    "all_player_data = pd.read_csv(datapath)\n",
    "all_player_data.sort_values('overall');\n",
    "player_data_without_gk = all_player_data[all_player_data.loc[:, 'player_positions'] != 'GK']\n",
    "numeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "player_data = player_data_without_gk.select_dtypes(include=numeric_dtypes)\n",
    "player_data = player_data.dropna(axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variabler\n",
    "Vi er interesserte i å forklare totale ferdigheter, ``overall``, som funksjon av alle andre variabler. Disse blir da hhv. $y$ og $X$. Både ``overall``, og ``potential`` droppes fra $X$, siden disse henger så tett sammen. Jeg splitter datasettet opp i et test- og et treningssett, half ´n half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_data_train, player_data_test = train_test_split(player_data, test_size=0.2, random_state=1997)\n",
    "y = player_data_train.loc[:, 'overall'].to_numpy()\n",
    "y_test = player_data_test.loc[:, 'overall'].to_numpy()\n",
    "X = player_data_train.drop(['overall', 'potential'], axis='columns').to_numpy()\n",
    "X_test = player_data_test.drop(['overall', 'potential'], axis='columns').to_numpy()\n",
    "n = len(y)\n",
    "n_test = len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MSE for prediksjoner på treningssett: 4.64682588998231\nMSE for prediksjoner på testsett: 4.815898694402428\n"
    }
   ],
   "source": [
    "mlr_fit = LinearRegression().fit(X, y)\n",
    "y_hat = mlr_fit.predict(X)\n",
    "y_hat_test = mlr_fit.predict(X_test)\n",
    "mlr_mse_train = sum((y_hat - y)**2)/n\n",
    "mlr_mse_test = sum((y_hat_test - y_test)**2)/n_test\n",
    "print(f\"MSE for prediksjoner på treningssett: {mlr_mse_train}\")\n",
    "print(f\"MSE for prediksjoner på testsett: {mlr_mse_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Litt (men ikke særlig) avhengig av hvordan man deler opp i test- og treningssett ser vi at MSE for prediksjonene til denne estimatoren ligger på ca. $4,6$ for treningssett, og $4,8$ for testsett. Ikke spesielt imponerende, og heller ikke spesielt lovende når man tenker på at LS eksplisitt minimerer MSE for et gitt datasett.\n",
    "\n",
    "Vi gir likevel ikke opp. Kanskje dataen kan si oss noe om hvilke variabler som best forklarer ``overall``? I så fall burde LS med $\\ell_1$-regularisering (LASSO) gi sammenlignbare resultater som ren LS. Vi prøver.\n",
    "\n",
    "TODO: forsøk mange ulike verdier av $\\lambda$, og test på testsett."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "MSE for prediksjoner på treningssett: 9.140278446535188\nMSE for prediksjoner på testsett: 9.609342104846986\nAntall ikke-null elementer i tilpasset modell: 13\n"
    }
   ],
   "source": [
    "lasso_fit = Lasso(alpha=10).fit(X, y)\n",
    "y_hat = lasso_fit.predict(X)\n",
    "y_hat_test = lasso_fit.predict(X_test)\n",
    "mlr_mse_train = sum((y_hat - y)**2)/n\n",
    "mlr_mse_test = sum((y_hat_test - y_test)**2)/n_test\n",
    "print(f\"MSE for prediksjoner på treningssett: {mlr_mse_train}\")\n",
    "print(f\"MSE for prediksjoner på testsett: {mlr_mse_test}\")\n",
    "print(f\"Antall ikke-null elementer i tilpasset modell: {lasso_fit.sparse_coef_.count_nonzero()}\")"
   ]
  }
 ]
}